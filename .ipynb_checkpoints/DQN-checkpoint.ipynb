{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'Resources/MagicCube/code/')\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "from bitstring import BitArray\n",
    "import math\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from cube import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 3 #cube size\n",
    "\n",
    "#Q-learning parameters\n",
    "r = 0.15\n",
    "gamma = 1 / (1 + r) #discount of the model\n",
    "C = 1.\n",
    "epsilon = 0.05\n",
    "beta = 3./4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_actions(N): #rotate by +90째 / by -90째 \n",
    "    actions = []\n",
    "    c = Cube(N)\n",
    "    for face_name in [\"F\",\"U\",\"R\"]: #the list is in the end ['U','D','F']\n",
    "        for layer in range(c.N):\n",
    "            for times in [1,-1]:\n",
    "                actions.append([face_name,layer,times])\n",
    "    return actions\n",
    "\n",
    "# def reward_cube(c):\n",
    "#     edges = computeEdges(c)\n",
    "#     corners = computeCorners(c)\n",
    "#     ncf = numCompleteFaces(c)\n",
    "#     nce = numCompleteEdges(c,edges)\n",
    "#     ncc = numCompleteCorners(c,corners)\n",
    "    \n",
    "# #     return (-1 + 10*ncf + 2*nce + 3*ncc + 100*(ncf == 6))/700\n",
    "#     return (ncf == 6)\n",
    "\n",
    "def reward_cube(c):\n",
    "    ncf = numCompleteFaces(c)\n",
    "    return (-1 + entropy(c) + 100*(ncf == 6))/100\n",
    "\n",
    "def entropy(c):\n",
    "    ent = 0\n",
    "    for f in range(6):\n",
    "        pi = len(np.unique(c.stickers[f]))\n",
    "        ent -= pi*np.log(pi)       \n",
    "    return ent\n",
    "        \n",
    "\n",
    "def state_cube(c):\n",
    "    #determining the new state\n",
    "    edges = computeEdges(c)\n",
    "    corners = computeCorners(c)\n",
    "    edges_state = []\n",
    "    corners_state = []\n",
    "    faces_state = []\n",
    "#     for e in edges:\n",
    "#         edges_state.append(e.isDone(c))\n",
    "    for corner in corners:\n",
    "        corners_state.append(corner.isDone(c))\n",
    "    nFaces = 6\n",
    "    for f in range(nFaces):\n",
    "        faces_state.append(np.sum(c.stickers[f] != c.stickers[f,0,0]) == 0)\n",
    "#     #conversion from binary list to int\n",
    "#     e = BitArray(edges_state).uint\n",
    "    c = BitArray(corners_state).uint\n",
    "    f = BitArray(faces_state).uint\n",
    "#     ncf = numCompleteFaces(c)\n",
    "#     nce = numCompleteEdges(c,edges)\n",
    "#     ncc = numCompleteCorners(c,corners)\n",
    "#     return ncf,nce,ncc\n",
    "    return c,f\n",
    "\n",
    "def test_function_state_cube():\n",
    "    c = Cube(3)\n",
    "    print(state_cube(c))\n",
    "    c.randomize(1)\n",
    "    print(state_cube(c))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['F', 0, 1],\n",
       " ['F', 0, -1],\n",
       " ['F', 1, 1],\n",
       " ['F', 1, -1],\n",
       " ['F', 2, 1],\n",
       " ['F', 2, -1],\n",
       " ['U', 0, 1],\n",
       " ['U', 0, -1],\n",
       " ['U', 1, 1],\n",
       " ['U', 1, -1],\n",
       " ['U', 2, 1],\n",
       " ['U', 2, -1],\n",
       " ['R', 0, 1],\n",
       " ['R', 0, -1],\n",
       " ['R', 1, 1],\n",
       " ['R', 1, -1],\n",
       " ['R', 2, 1],\n",
       " ['R', 2, -1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = all_actions(N) #rotate by +90째 / by -90째 \n",
    "nb_actions = len(actions)\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network():\n",
    "    \n",
    "    def __init__(self,W1,W2):\n",
    "        \n",
    "        self.W1 = W1\n",
    "        self.W2 = W2\n",
    "        \n",
    "        self.Q1 = tf.matmul(x/6,self.W1)# + b1\n",
    "        self.Qs1 = tf.nn.tanh(self.Q1)\n",
    "        self.Q2 = tf.matmul(self.Qs1,self.W2)#tf.nn.relu(tf.matmul(Qs1,W2))# + b2)\n",
    "        \n",
    "        self.sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "         \n",
    "        self.network_params = tf.trainable_variables()\n",
    "        self.tau = 1.\n",
    "    \n",
    "    \n",
    "    \n",
    "    def update_target_network(self, trainNet):\n",
    "        \n",
    "        self.update_target_network_params = \\\n",
    "            [self.network_params[i].assign(tf.mul(trainNet.network_params[i], self.tau) + \\\n",
    "                tf.mul(self.network_params[i], 1. - self.tau))\n",
    "                for i in range(len(self.network_params))]\n",
    "        \n",
    "        self.sess.run(self.update_target_network_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_init=Cube(3)\n",
    "\n",
    "resume = False\n",
    "\n",
    "#==============================================================================\n",
    "#                           DEFINE NEURAL NETWORK\n",
    "#==============================================================================\n",
    "\n",
    "# sess = tf.InteractiveSession() \n",
    "with tf.device(\"/gpu:0\"):\n",
    " \n",
    "    x = tf.placeholder(tf.float32, shape=[None,6*c_init.N**2])\n",
    "    # act = tf.placeholder(tf.float32, shape=[nb_actions,None])\n",
    "    # Q_ = tf.placeholder(tf.float32, shape=[None,1])\n",
    "    Q_ = tf.placeholder(tf.float32, shape=[None,nb_actions])\n",
    " \n",
    " \n",
    "    if not resume:\n",
    "        W1 = tf.Variable(tf.random_normal([6*c_init.N**2,5000], stddev=1e-2))\n",
    "        # b1 = tf.Variable(tf.random_normal([6*c_init.N**2], stddev=1e-6))\n",
    " \n",
    "        W2 = tf.Variable(tf.random_normal([5000,nb_actions], stddev=1e-2))\n",
    "        # b2 = tf.Variable(tf.random_normal([nb_actions], stddev=1e-6))  \n",
    "    else:\n",
    "        load = pickle.load(open('save.p', 'rb'))\n",
    "        W1 = tf.Variable(load[0])\n",
    "        W2 = tf.Variable(load[1])\n",
    " \n",
    " \n",
    "    trainNet = network(W1,W2)\n",
    "    \n",
    "    targetNet = network(W1,W2)\n",
    "    \n",
    "#     Qs = targetNet.Q2\n",
    "\n",
    "    \n",
    "    loss_function = tf.reduce_mean(tf.square(tf.sub(Q_,targetNet.Q2)))\n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss_function)\n",
    "    \n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    trainNet.sess.run(init_op)\n",
    "    targetNet.sess.run(init_op)\n",
    "    \n",
    "#==============================================================================\n",
    "\n",
    "D = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DQN(c_init,Tmax,nb_episodes, n_moves):\n",
    "    \n",
    "    plt.ion()\n",
    "    done = 0\n",
    "    lActions = np.zeros(18)\n",
    "    print(\"moves\",\"\\t\",\"ep.\",\"\\t\",\"Loss Function\",\"\\t\",\"Min Q\",\"\\t\\t\", \"Reward\", \"\", \"NB.\",\"\\t\", \"Prcent.\",\"\\t\",\"Mn. Prcent.\")\n",
    "    \n",
    "    global targetNet\n",
    "        \n",
    "    mineps = .1\n",
    "    def eps(episode):\n",
    "        return min(1,max(.1,100/(1+episode)))\n",
    "    \n",
    "    lenBatch = 10*Tmax\n",
    "    \n",
    "    episode = 1\n",
    "    \n",
    "    percentDone = []\n",
    "    \n",
    "    tries = 1\n",
    "    \n",
    "    dones = np.empty([0])\n",
    "    \n",
    "    while np.sum(dones[-1000:])/min(1000,tries) < .8 and episode < nb_episodes:  \n",
    "        \n",
    "        episode += 1\n",
    "        \n",
    "        s = copy.deepcopy(c_init)\n",
    "        s.randomize(n_moves) #we randomize n_moves times in order to have a \"well mixed\" cube\n",
    "        #s.move(\"R\",2,-1)\n",
    "        cum_reward = []\n",
    "        \n",
    "        tries += 1\n",
    "        done = 0\n",
    "            \n",
    "        for i in range(Tmax):\n",
    "            \n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            S = copy.copy(np.reshape(s.stickers,(1, 54)))\n",
    "            Qout = trainNet.sess.run(trainNet.Q2,feed_dict={x:S})\n",
    "            if(rd.random() > eps(episode)):\n",
    "                a = np.argmax(Qout)\n",
    "            else:\n",
    "                a = rd.randint(0,nb_actions-1)\n",
    "        \n",
    "            lActions[a] += 1\n",
    "            \n",
    "            #print(actions[a])\n",
    "            #print(Qout)\n",
    "            #Get new state and reward from environment\n",
    "            f,l,d = actions[a]\n",
    "            #print(actions[a])\n",
    "            s.move(f,l,d)            \n",
    "            r = reward_cube(s)\n",
    "            cum_reward.append(r)\n",
    "            D.append(copy.copy([S, a, r, np.reshape(s.stickers,(1, 54)), numCompleteFaces(s)]))\n",
    "            \n",
    "            #print(S)\n",
    "            #print(np.reshape(s.stickers,(1, 54)))\n",
    "            \n",
    "#==============================================================================\n",
    "#             #Obtain the Q' values by feeding the new state through our network\n",
    "#             Qprime = sess.run(Q2,feed_dict={x:np.reshape(s.stickers,(1, 54))})\n",
    "#             #Obtain maxQ' and set our target value for chosen action.\n",
    "#             maxQprime = np.max(Qprime)\n",
    "#             targetQ = Qout\n",
    "#             targetQ[0,a] = r + gamma*maxQprime\n",
    "#             #Train our network using target and predicted Q values\n",
    "#                \n",
    "#             sess.run(train_step,feed_dict={Q_: targetQ, x: S})\n",
    "#==============================================================================\n",
    "            \n",
    "            #print(targetQ)\n",
    "        \n",
    "            cum_reward.append(r)\n",
    "            \n",
    "            \n",
    "            if numCompleteFaces(s) == 6:\n",
    "                done = 1\n",
    "                break\n",
    "            \n",
    "        dones = np.append(dones,done)\n",
    "            \n",
    "        \n",
    "# ============================================================================== \n",
    "#                           EXPERIENCE REPLAY      \n",
    "# ==============================================================================\n",
    "\n",
    "        if episode%lenBatch == 0:\n",
    "              Dshuf = D[-lenBatch:]\n",
    "              random.shuffle(Dshuf)\n",
    "#              batch = np.array(Dshuf[:lenBatch])\n",
    "              batch = np.array(Dshuf)\n",
    "              \n",
    "              tts = np.empty([0,nb_actions])\n",
    "            \n",
    "              for i in range(len(batch)):\n",
    "              \n",
    "                  faces_done = batch[i][-1]\n",
    "                \n",
    "                  Qprime = trainNet.sess.run(trainNet.Q2,feed_dict={x:batch[i][-2]})\n",
    "                  maxQprime = np.max(Qprime)\n",
    "                \n",
    "                  tt = trainNet.sess.run(trainNet.Q2,feed_dict={x:batch[i][0]})\n",
    "                  if faces_done == 6:\n",
    "                      tt[0,batch[i][1]] = batch[i][-3]\n",
    "                  else:\n",
    "                      tt[0,batch[i][1]] = batch[i][-3] + gamma*maxQprime\n",
    "              \n",
    "                  tts = np.concatenate((tts,tt),0)\n",
    "              \n",
    "              trainNet.sess.run(train_step,feed_dict={Q_: tts, x: batch[:,0][0]})\n",
    "\n",
    "# ============================================================================== \n",
    "#                           \n",
    "# ==============================================================================\n",
    "            \n",
    "\n",
    "        if episode%100 == 1:\n",
    "#             sess.run(loss_function,feed_dict={Q_: targetQ, x: S}),\"\\t\",\n",
    "            print(n_moves,\"\\t\",episode,\"\\t\",min(targetNet.sess.run(targetNet.Q2,feed_dict={x:S})[0]),\"\\t\", round(np.mean(cum_reward[-1]),2), \"\\t\", np.sum(dones[-1000:]),\"\\t\", round(100*np.sum(dones[-1000:])/min(1000,tries),2),\"\\t\", round(100*np.sum(dones)/tries,2))\n",
    "            percentDone.append(100*np.sum(dones[-1000:])/min(1000,tries))\n",
    "    #             print(lActions)\n",
    "#            print(np.var(sess.run(Q2,feed_dict={x:S})))\n",
    "        \n",
    "        if episode%1000 == 1:\n",
    "            targetNet.update_target_network(trainNet)\n",
    "            plt.clf()\n",
    "            plt.plot(percentDone, linewidth = 2)\n",
    "            plt.title(\"n_moves: \"+str(n_moves))\n",
    "            plt.pause(0.0001)\n",
    "            topickle = [targetNet.sess.run(targetNet.W1),targetNet.sess.run(targetNet.W2)]\n",
    "            pickle.dump(topickle, open('save.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def longTrain(c_init,n_moves_max):\n",
    "\n",
    "    for i in range(1,1+n_moves_max):\n",
    "        print(\"==============================================================================\")\n",
    "        print(\"\\t\",i,\"Moves\",\"\\t\")\n",
    "        print(\"==============================================================================\")\n",
    "        DQN(c_init=c_init,Tmax=i,nb_episodes=1000000,n_moves = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "\t 1 Moves \t\n",
      "==============================================================================\n",
      "moves \t ep. \t Loss Function \t Min Q \t\t Reward  NB. \t Prcent. \t Mn. Prcent.\n",
      "1 \t 101 \t -0.0476631 \t -0.17 \t 7.0 \t 6.93 \t 6.93\n",
      "1 \t 201 \t -0.0447876 \t -0.17 \t 10.0 \t 4.98 \t 4.98\n",
      "1 \t 301 \t -0.0279199 \t -0.17 \t 17.0 \t 5.65 \t 5.65\n",
      "1 \t 401 \t -0.0476631 \t -0.17 \t 19.0 \t 4.74 \t 4.74\n",
      "1 \t 501 \t -0.0375655 \t -0.07 \t 25.0 \t 4.99 \t 4.99\n",
      "1 \t 601 \t -0.0375655 \t -0.14 \t 33.0 \t 5.49 \t 5.49\n",
      "1 \t 701 \t -0.0411841 \t -0.07 \t 41.0 \t 5.85 \t 5.85\n",
      "1 \t 801 \t -0.0358809 \t -0.14 \t 50.0 \t 6.24 \t 6.24\n",
      "1 \t 901 \t -0.0411841 \t -0.17 \t 51.0 \t 5.66 \t 5.66\n",
      "1 \t 1001 \t -0.0375655 \t -0.07 \t 62.0 \t 6.2 \t 6.19\n",
      "1 \t 1101 \t -0.0368972 \t -0.14 \t 67.0 \t 6.7 \t 6.72\n",
      "1 \t 1201 \t -0.0476631 \t -0.17 \t 76.0 \t 7.6 \t 7.16\n",
      "1 \t 1301 \t -0.0620681 \t -0.07 \t 80.0 \t 8.0 \t 7.46\n",
      "1 \t 1401 \t -0.0447876 \t -0.17 \t 82.0 \t 8.2 \t 7.21\n",
      "1 \t 1501 \t -0.0620387 \t -0.17 \t 82.0 \t 8.2 \t 7.13\n",
      "1 \t 1601 \t -0.0507095 \t -0.17 \t 86.0 \t 8.6 \t 7.43\n",
      "1 \t 1701 \t -0.0691374 \t 0.99 \t 87.0 \t 8.7 \t 7.52\n",
      "1 \t 1801 \t -0.0488472 \t -0.17 \t 82.0 \t 8.2 \t 7.33\n",
      "1 \t 1901 \t -0.0476631 \t -0.14 \t 86.0 \t 8.6 \t 7.21\n",
      "1 \t 2001 \t -0.043949 \t -0.14 \t 81.0 \t 8.1 \t 7.15\n",
      "1 \t 2101 \t -0.0507095 \t -0.17 \t 81.0 \t 8.1 \t 7.38\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3f2b0fd7c44a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/gpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlongTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCube\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#    DQN(c_init=Cube(3),Tmax=int(sys.argv[4]),nb_episodes=int(sys.argv[2]),n_moves = int(sys.argv[3]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-2e2ab6c0e471>\u001b[0m in \u001b[0;36mlongTrain\u001b[0;34m(c_init, n_moves_max)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Moves\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==============================================================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_moves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-0e5df050bb9c>\u001b[0m in \u001b[0;36mDQN\u001b[0;34m(c_init, Tmax, nb_episodes, n_moves)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mepisode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_moves\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#we randomize n_moves times in order to have a \"well mixed\" cube\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#s.move(\"R\",2,-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marc/anaconda3/lib/python3.5/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    180\u001b[0m                             raise Error(\n\u001b[1;32m    181\u001b[0m                                 \"un(deep)copyable object of type %s\" % cls)\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marc/anaconda3/lib/python3.5/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, info, deep, memo)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marc/anaconda3/lib/python3.5/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marc/anaconda3/lib/python3.5/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFyCAYAAAB/b0lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6dac9b74a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    longTrain(Cube(3),10)\n",
    "#    DQN(c_init=Cube(3),Tmax=int(sys.argv[4]),nb_episodes=int(sys.argv[2]),n_moves = int(sys.argv[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topickle = [sess.run(W1),sess.run(W2)]\n",
    "pickle.dump(topickle, open('save.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Set learning parameters\n",
    "y = .99\n",
    "e = 0.1\n",
    "num_episodes = 2000\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_episodes):\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        rAll = 0\n",
    "        d = False\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < 99:\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            a,allQ = sess.run([predict,Qout],feed_dict={inputs1:np.identity(16)[s:s+1]})\n",
    "            if np.random.rand(1) < e:\n",
    "                a[0] = env.action_space.sample()\n",
    "            #Get new state and reward from environment\n",
    "            s1,r,d,_ = env.step(a[0])\n",
    "            #Obtain the Q' values by feeding the new state through our network\n",
    "            Q1 = sess.run(Qout,feed_dict={inputs1:np.identity(16)[s1:s1+1]})\n",
    "            #Obtain maxQ' and set our target value for chosen action.\n",
    "            maxQ1 = np.max(Q1)\n",
    "            targetQ = allQ\n",
    "            targetQ[0,a[0]] = r + y*maxQ1\n",
    "            #Train our network using target and predicted Q values\n",
    "            _,W1 = sess.run([updateModel,W],feed_dict={inputs1:np.identity(16)[s:s+1],nextQ:targetQ})\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            if d == True:\n",
    "                #Reduce chance of random action as we train the model.\n",
    "                e = 1./((i/50) + 10)\n",
    "                break\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "print \"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taken from https://gist.github.com/awjuliani/fffe41519166ee41a6bd5f5ce8ae2630#file-double-dueling-dqn-tutorial-ipynb\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if load_model == True:\n",
    "        print 'Loading Model...'\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    sess.run(init)\n",
    "    updateTarget(targetOps,sess) #Set the target network to be equal to the primary network.\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Set the target network to be equal to the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        #Get all experiences from this episode and discount their rewards.\n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.cptk')\n",
    "            print \"Saved Model\"\n",
    "        if len(rList) % 10 == 0:\n",
    "            print total_steps,np.mean(rList[-10:]), e\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.cptk')\n",
    "print \"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###BACKUP DON'T TOUCH PLEASE ###\n",
    "\n",
    "\n",
    "# def DQN(c_init,Tmax,nb_episodes, n_moves):\n",
    "    \n",
    "#     done = 0\n",
    "#     lActions = np.zeros(18)\n",
    "#     print(\"ep.\",\"\\t\",\"Loss Function\",\"\\t\",\"Min Q\",\"\\t\\t\", \"Reward\", \"\", \"NB.\",\"\\t\", \"Prcent.\")\n",
    "#     def eps(episode):\n",
    "#         return min(1,max(.05,100/(1+episode)))\n",
    "    \n",
    "#     episode = 1\n",
    "#     tries = 0\n",
    "    \n",
    "#     for k in range(nb_episodes):  \n",
    "        \n",
    "#         s = copy.deepcopy(c_init)\n",
    "#         s.randomize(n_moves) #we randomize n_moves times in order to have a \"well mixed\" cube\n",
    "#         cum_reward = []\n",
    "        \n",
    "#         tries += 1\n",
    "        \n",
    "#         for i in range(Tmax):\n",
    "            \n",
    "#             #transition \n",
    "#             S = np.reshape(s.stickers,(1, 54))\n",
    "#             if(rd.random() > eps(episode)):\n",
    "#                 a = np.argmax(Q2.eval({x:S}))\n",
    "#             else:\n",
    "#                 a = rd.randint(0,nb_actions-1)\n",
    "\n",
    "#             lActions[a] += 1\n",
    "#             f,l,d = actions[a]\n",
    "#             s.move(f,l,d)            \n",
    "#             R = reward_cube(s)\n",
    "#             cum_reward.append(R)\n",
    "#             D.append([S, a, R, np.reshape(s.stickers,(1, 54))])\n",
    "            \n",
    "#             if numCompleteFaces(s) == 6:\n",
    "#                 done += 1\n",
    "                \n",
    "#                 Dshuf = D\n",
    "#                 random.shuffle(Dshuf)\n",
    "#                 batch = np.array(Dshuf[:10])\n",
    "\n",
    "#                 tts = np.empty([0,1])\n",
    "\n",
    "#                 for i in range(len(batch)):\n",
    "\n",
    "#                     faces_done = np.sum([np.sum([batch[i][-1][0][f*9+j] != batch[i][-1][0][f*9] for j in range(9)]) == 0 for f in range(6)])\n",
    "\n",
    "#                     if faces_done == 6:\n",
    "#                         tt = batch[i][-2]\n",
    "#                     else:\n",
    "#                         tt = batch[i][-2] + gamma*max(Q2.eval({x:batch[i][-1]})[0])\n",
    "\n",
    "#                     tts = np.append(tts,tt)\n",
    "\n",
    "#                 tts = np.reshape(tts,(-1, 1))\n",
    "\n",
    "#                 action = np.reshape([[i == batch[j,1] for i in range(nb_actions)] for j in range(len(batch))], (-1,len(batch)))\n",
    "#                 train_step.run(feed_dict={Q_: tts, x: batch[:,0][0], act: action})\n",
    "                \n",
    "        \n",
    "# #         if episode%10 == 1:\n",
    "#                 print(episode,\"\\t\",loss_function.eval({Q_: tts, x:batch[:,0][0], act: action}),\"\\t\",min(Q2.eval({x:batch[:,0][0]})[0]),\"\\t\", round(cum_reward[-1],2), \"\\t\", done,\"\\t\", round(100*done/tries,2))\n",
    "#         #             print(lActions)\n",
    "#                 print(np.var(Q2.eval({x:batch[:,0][0]})[0]))\n",
    "            \n",
    "#                 break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
